{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3wTXT6aIc6x"
      },
      "source": [
        "# Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w72VdIyXatJK",
        "outputId": "3b409047-972c-4ea4-cc3b-216b80511061"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "!pip install transformers\n",
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXkiBa6_ITdj",
        "outputId": "de47f4fc-d8ae-431b-f03f-49b13d7c5e2f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import string\n",
        "import joblib\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.collocations import BigramCollocationFinder,BigramAssocMeasures\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('all')\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ysH2KafJBwO"
      },
      "source": [
        "# Cargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "9zWHZy5QatJN",
        "outputId": "01e42ec2-ac36-4569-fa2e-43645347b1fb"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('trackings.csv', sep=';')\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siDOK8jHFDsC",
        "outputId": "95b809a3-8e9d-408b-e2a1-a2cab86c441d"
      },
      "outputs": [],
      "source": [
        "columnas = df.columns\n",
        "print(columnas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKMhgcKMNVrM"
      },
      "source": [
        "# Preparación de datos\n",
        "## Unificación de comentarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "dvVG9Je5lr0g",
        "outputId": "9c915c75-5844-4f50-ad52-f2e4876a9dad"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby('IdTracking').apply(\n",
        "    lambda x: pd.Series({\n",
        "        'Des': x['Des'].iloc[0],  # Cargar 'Des' solo una vez (el primer valor del grupo)\n",
        "        'Des_Combined': ' '.join(x['Des.1'].astype(str)),\n",
        "        'IdTipoTracking': x['IdTipoTracking'].iloc[0],\n",
        "        'IdPrioridad': x['IdPrioridad'].iloc[0],\n",
        "        'IdTipoTarea': x['IdTipoTarea'].iloc[0],\n",
        "        'IdComponente': x['IdComponente'].iloc[0],\n",
        "        'IdPropuesta': x['IdPropuesta'].iloc[0],\n",
        "        'IdCuenta': x['IdCuenta'].iloc[0],\n",
        "        'FecAlt': x['FecAlt'].iloc[0],\n",
        "        'IdUsuarioAlt': x['IdUsuarioAlt'].iloc[0],\n",
        "        'FecAsi': x['FecAsi'].iloc[0],\n",
        "        'IdUsuarioAsi': x['IdUsuarioAsi'].iloc[0],\n",
        "        'IdEstado': x['IdEstado'].iloc[0],\n",
        "        'IdTipoEstado': x['IdTipoEstado'].iloc[0],\n",
        "        'HorEst': x['HorEst'].iloc[0],\n",
        "        'MinEst': x['MinEst'].iloc[0],\n",
        "        'Inter': x['Inter'].iloc[0],\n",
        "        'Exter': x['Exter'].iloc[0],\n",
        "        'IdHito': x['IdHito'].iloc[0],\n",
        "        'IdVersion': x['IdVersion'].iloc[0],\n",
        "        'FecVto': x['FecVto'].iloc[0],\n",
        "        'HorDes': x['HorDes'].iloc[0],\n",
        "        'IdProducto': x['IdProducto'].iloc[0],\n",
        "        'IdCategoria': x['IdCategoria'].iloc[0],\n",
        "        'AplMan': x['AplMan'].iloc[0],\n",
        "        'Hordesdes': x['Hordesdes'].iloc[0],\n",
        "        'Hordestes': x['Hordestes'].iloc[0],\n",
        "        'Horesttes': x['Horesttes'].iloc[0],\n",
        "        'Horestdes': x['Horestdes'].iloc[0],\n",
        "        'HorCli': x['HorCli'].iloc[0],\n",
        "        'ConCan': x['ConCan'].iloc[0],\n",
        "        'Obs': x['Obs'].iloc[0],\n",
        "        'IdTareaProyecto': x['IdTareaProyecto'].iloc[0],\n",
        "        'IdSubtipoProducto': x['IdSubtipoProducto'].iloc[0],\n",
        "        'IdTrackingRelacionado': x['IdTrackingRelacionado'].iloc[0],\n",
        "        'IdComplejidad': x['IdComplejidad'].iloc[0],\n",
        "        'FecUltMod': x['FecUltMod'].iloc[0],\n",
        "        'IdServidor': x['IdServidor'].iloc[0],\n",
        "        'Facturable': x['Facturable'].iloc[0]\n",
        "    })\n",
        ").reset_index()\n",
        "\n",
        "df_grouped.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srJJL_RNFDsE"
      },
      "source": [
        "## Preparación del texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "po0ls2MMFDsE",
        "outputId": "3cb5a13e-6822-4747-b216-c012455c5a4b"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto(text):\n",
        "  # Convertir a minúsculas\n",
        "  text = text.lower()\n",
        "  # Eliminar signos de puntuación\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "  # Reemplazar tildes\n",
        "  text = text.replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('Á', 'A').replace('É', 'E').replace('Í', 'I').replace('Ó', 'O').replace('Ú', 'U')\n",
        "  # Eliminar números y caracteres especiales\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  # Eliminar espacios en blanco adicionales\n",
        "  text = ' '.join(text.split())\n",
        "  # Tokenizar el texto\n",
        "  tokens = word_tokenize(text, language='spanish')\n",
        "  # Eliminar stop words\n",
        "  stop_words = set(stopwords.words('spanish'))\n",
        "  tokens = [word for word in tokens if not word in stop_words]\n",
        "  # Lematizar las palabras\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "  # Unir los tokens de nuevo en una cadena\n",
        "  processed_text = ' '.join(tokens)\n",
        "  return processed_text\n",
        "\n",
        "df_grouped['Des'] = df_grouped['Des'] + ' ' + df_grouped['Des_Combined']\n",
        "df_grouped['Des'] = df_grouped['Des'].apply(limpiar_texto)\n",
        "df_grouped = df_grouped.drop(columns=['Des_Combined'])\n",
        "\n",
        "df_grouped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxZS4HcXFDsE"
      },
      "source": [
        "### Realizamos un análisis de Sentimientos de la variable Des"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "jGBNAZoXx4cu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cargar el modelo de análisis de sentimientos\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Función para analizar el sentimiento de un texto\n",
        "def analyze_sentiment(text):\n",
        "  #Se trunca el texto a un máximo de 512 tokens para que se ajuste al modelo BERT.\n",
        "  result = sentiment_pipeline(text[:512])\n",
        "  return result[0]['label'], result[0]['score']\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df_grouped[['sentiment_label', 'sentiment_score']] = df_grouped['Des'].apply(lambda x: pd.Series(analyze_sentiment(x)))\n",
        "\n",
        "# Mapear las etiquetas de sentimiento a valores numéricos\n",
        "sentiment_mapping = {'1 star': 1, '2 stars': 2, '3 stars': 3, '4 stars': 4, '5 stars': 5}\n",
        "df_grouped['des_sentimiento'] = df_grouped['sentiment_label'].map(sentiment_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLazz_HRFDsF"
      },
      "source": [
        "### Realizamos una Clasificación de texto de la variable Des"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Rio4QIrhqe",
        "outputId": "2a943c08-2728-4bd0-a551-ed16aee5fc44"
      },
      "outputs": [],
      "source": [
        "# Cargar el pipeline para clasificación de texto con BERT\n",
        "classifier = pipeline('text-classification', model='dccuchile/bert-base-spanish-wwm-uncased')\n",
        "\n",
        "# Función para clasificar el texto\n",
        "def classify_text(text):\n",
        "  result = classifier(text[:775])\n",
        "  return result[0]['label'], result[0]['score']\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df_grouped[['classification_label', 'classification_score']] = df_grouped['Des'].apply(lambda x: pd.Series(classify_text(x)))\n",
        "df_grouped['des_clasificacion'] = df_grouped['classification_label'].map({'LABEL_0': False, 'LABEL_1': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUici4YgFDsG"
      },
      "source": [
        "## Agregamos la variable FecAlt_diff_minutes que representa el tiempo en minutos desde que un issue fue creado hasta su primera atención"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FSRB8Y9sI4GM"
      },
      "outputs": [],
      "source": [
        "# Convertir las columnas 'FecAlt' y 'FecAlt.1' a formato datetime\n",
        "df['FecAlt'] = pd.to_datetime(df['FecAlt'], format='%d/%m/%Y %H:%M')\n",
        "df['FecAlt.1'] = pd.to_datetime(df['FecAlt.1'], format='%d/%m/%Y %H:%M')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ej0grak2FDsG",
        "outputId": "1b9761fc-e8ee-4510-f83a-34f9d5611906"
      },
      "outputs": [],
      "source": [
        "# Find the minimum FecAlt for each IdTracking in df_grouped\n",
        "min_fecalt = df.groupby('IdTracking')['FecAlt.1'].min().reset_index()\n",
        "df_diff_min = df_grouped\n",
        "# Merge the minimum FecAlt values back into the original DataFrame\n",
        "df_diff_min = df_diff_min.merge(min_fecalt, on=['IdTracking'], how='left')\n",
        "\n",
        "#Convertimos las columnas a fechas\n",
        "df_diff_min['FecAlt'] = pd.to_datetime(df_diff_min['FecAlt'], format='%d/%m/%Y %H:%M')\n",
        "df_diff_min['FecAlt.1'] = pd.to_datetime(df_diff_min['FecAlt.1'], format='%d/%m/%Y %H:%M')\n",
        "\n",
        "# Calculate the difference in minutes between FecAlt and FecAlt.1\n",
        "df_grouped['FecAlt_diff_minutes'] = (df_diff_min['FecAlt.1'] - df_diff_min['FecAlt']).dt.total_seconds() / 60\n",
        "\n",
        "df_grouped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiDi3i4wFDsF"
      },
      "source": [
        "### Eliminamos las columnas no deseadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ZL3xai08j8Vz",
        "outputId": "5147f07b-5c30-4c0c-c84c-41a815cfe985"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Eliminar las columnas especificadas\n",
        "df_grouped = df_grouped.drop(columns=[\n",
        "      'IdTipoTarea', 'IdComponente', 'IdPropuesta', 'FecAlt','IdUsuarioAlt', 'FecAsi', 'IdUsuarioAsi', 'IdTipoEstado',\n",
        "      'MinEst', 'IdHito', 'IdVersion', 'FecVto', 'HorDes', 'AplMan', 'Hordesdes',\n",
        "      'Hordestes', 'Horesttes', 'Horestdes', 'HorCli', 'Obs','IdTareaProyecto', 'IdSubtipoProducto', 'IdTrackingRelacionado',\n",
        "      'FecUltMod', 'IdServidor', 'sentiment_label','sentiment_score', 'classification_score', 'classification_label'\n",
        "])\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para verificar el resultado\n",
        "df_grouped.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ceDBZkatJR"
      },
      "source": [
        "## Corregimos los valores erróneos de la variable Facturable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "BVTJl72KatJS",
        "outputId": "a5ca67a1-0433-4c44-f5e2-c52f8f5d1481"
      },
      "outputs": [],
      "source": [
        "# Reemplazamos los #n/a por 0\n",
        "df_grouped['Facturable'] = df_grouped['Facturable'].replace('#N/D', 0)\n",
        "df_grouped['Facturable'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEovOY6D2zOF"
      },
      "source": [
        "## Vectorizamos la variable Des"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5OhABeVmulZ6",
        "outputId": "7e8b707d-0df2-4ec0-ddf1-662251e1804b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Vectorización con TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df_grouped['Des'])\n",
        "\n",
        "# Convertir la matriz TF-IDF a un DataFrame de pandas\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Concatenar el DataFrame de TF-IDF con el DataFrame original\n",
        "df_grouped = pd.concat([df_grouped, tfidf_df], axis=1)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "df_grouped.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qKyQ6_2zOG"
      },
      "source": [
        "## Entrenamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dGhjeVywcf2",
        "outputId": "572a7d25-539e-4f6a-97cc-e04d60941814"
      },
      "outputs": [],
      "source": [
        "df_grouped['Facturable'] = df_grouped['Facturable'].astype(int)\n",
        "# Import the necessary library\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_grouped.drop(['Facturable', 'Des'], axis=1)\n",
        "y = df_grouped['Facturable']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a LightGBM dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "# Define the parameters for the model\n",
        "# OrderedDict([('colsample_bytree', 0.9967880717646387), ('learning_rate', 0.0977729735815334), ('max_depth', 10), ('n_estimators', 161), ('num_leaves', 31), ('subsample', 0.7797370559774017)]) <- optimización bayesiana\n",
        "# OrderedDict([('colsample_bytree', 0.8269448351098192), ('learning_rate', 0.05251549392151682), ('max_depth', 9), ('n_estimators', 100), ('num_leaves', 27), ('subsample', 0.5)]) <- optimización bayesiana\n",
        "# {'feature_fraction': 1.0, 'learning_rate': 0.05, 'n_estimators': 300, 'num_leaves': 50} <- se obtuvo por GridSearch\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'colsample_bytree': 0.9967880717646387,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': 10,\n",
        "    'subsample': 0.7797370559774017,\n",
        "    'learning_rate': 0.0977729735815334,\n",
        "    'feature_fraction': 1.0,\n",
        "    'n_estimators': 161\n",
        "}\n",
        "\n",
        "\n",
        "# Entrenamos el modelo\n",
        "model = lgb.train(params,\n",
        "                  train_data,\n",
        "                  num_boost_round=100,\n",
        "                  valid_sets=[test_data],\n",
        "                  callbacks=[lgb.early_stopping(stopping_rounds=10)]) # Use early_stopping callback\n",
        "\n",
        "# Predecimos el subconjunto Test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred_binary = [1 if p > 0.50 else 0 for p in y_pred]\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred_binary))\n",
        "print(confusion_matrix(y_test, y_pred_binary))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRvyh56M2zOG"
      },
      "source": [
        "## Dibujamos el area bajo la curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gUld_FownwAi",
        "outputId": "b3af4275-1c0d-4a5b-beb7-42b542bd8287"
      },
      "outputs": [],
      "source": [
        "# Obtener las tasas de falsos positivos, tasas de verdaderos positivos y umbrales\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "# Calcular el área bajo la curva ROC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Dibujar la curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTjQhxlh2zOH"
      },
      "source": [
        "## Creamos la matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "GAogK2kin5Rw",
        "outputId": "e33ca71f-fd51-41e8-ae74-2f659fb27ea0"
      },
      "outputs": [],
      "source": [
        "# Dibujar la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Facturable', 'Facturable'])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nii7-K94atJb"
      },
      "source": [
        "# Uso del modelo en otros scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5waxDP3fatJb",
        "outputId": "f6e1fc2b-f51c-4a86-cb93-9288ecb61f70"
      },
      "outputs": [],
      "source": [
        "# Specify the file path to save the model\n",
        "model_path = 'model.pkl'\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "lc6pFSPMatJb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Specify the file path of the saved model\n",
        "model_path = 'model.pkl'\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load(model_path)\n",
        "\n",
        "# Now you can use the loaded model for predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
